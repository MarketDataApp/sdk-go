#!/usr/bin/env python3
import sys
import re

# Central mapping of URLs to their corresponding title and sidebar position
URL_TO_INFO = {
    "https://www.marketdata.app/docs/api/indices/candles": {"title": "Candles", "sidebar_position": 1},
    # Add more mappings as needed
}

def add_anchor_tags(content):
    """Process the parameters block of text as specified, including 'Setter Methods' and 'Execution Methods'. 
    Insert <a href="#"> before and </a> after lines that start with a dash (-)."""
    lines = content.split('\n')
    processed_lines = []
    processing = False
    found_first_dash = False  # Variable to track the first dash

    for line in lines:
        if (match := line.strip()) in ['#### Setter Methods', '#### Execution Methods', '#### Methods', '#### Generated By']:
            processing = True
            matched_string = match  # Keep track of which string matched
            found_first_dash = False  # Reset for each new section
            processed_lines.append(line)
            continue
        if processing:
            if not found_first_dash:
                if line.strip() == '':
                    processed_lines.append(line)
                    continue
                elif not line.lstrip().startswith('-'):
                    processed_lines.append(line)
                    continue
                else:
                    found_first_dash = True  # Found the first dash, start processing lines
            if line.startswith('-'):
                if matched_string != '#### Generated By':
                    previous_lines = lines[:lines.index(line)]
                    type_word = ""
                    for prev_line in reversed(previous_lines):
                        if prev_line.strip().startswith("type "):
                            type_word = prev_line.split()[1]
                            break
                    anchor = line[line.find('`')+1:line.find('(')].strip()
                    # Insert <a href="#"> before and </a> after the line
                    processed_lines.append('- ' + f'<a href="#{type_word}.{anchor}">' +'`' + line[3:] + '</a>')
                else:
                    anchor = line[line.find('`')+1:line.find('(')].strip()
                    # Insert <a href="#"> before and </a> after the line
                    processed_lines.append(f'<a href="#{anchor}">')
                    processed_lines.append(line)
                    processed_lines.append('</a>')  # Ensure an additional new line after closing tag for better readability
            elif line.strip() == '' or line.startswith('  '):
                processed_lines.append(line)
                continue
            else:
                # Stop processing if the line does not start with a dash
                processing = False
                processed_lines.append(line)
        else:
            processed_lines.append(line)

    return '\n'.join(processed_lines)

def move_all_struct_definitions(content):
    """Move all struct definition blocks right after their type documentation."""
    import re

    # Pattern to find struct type documentation
    struct_doc_pattern = re.compile(r"## type (\w+)")
    # Pattern to find struct definition blocks
    struct_def_pattern_template = r"(```go\s+type {}\s.*?```)"
    
    # Find all struct names from the documentation
    struct_names = struct_doc_pattern.findall(content)

    for struct_name in struct_names:
        # Create a pattern for the current struct definition
        struct_def_pattern = re.compile(struct_def_pattern_template.format(struct_name), re.DOTALL)
        
        # Find the struct definition block
        struct_def_match = struct_def_pattern.search(content)
        if not struct_def_match:
            continue  # Skip if struct definition block not found

        struct_def_block = struct_def_match.group(1)

        # Remove the original struct definition block from the content
        content = struct_def_pattern.sub('', content, count=1)

        # Insert the struct definition block right after the struct type documentation
        content = re.sub(
            rf"(## type {struct_name}\s*\n)",
            r'\1' + struct_def_block + '\n\n',
            content,
            count=1
        )

    return content

def correct_escaping_in_links(content):
    """Correct escaping in markdown links that start with [/v1 and enclose URL text in backticks if it contains { or }."""
    # Regular expression to match the pattern
    pattern = re.compile(r'(\[/v1[^\]]+\])')
    
    def remove_escapes_and_check_braces(match):
        # Remove backslashes from the matched string
        cleaned_match = match.group(0).replace('\\', '')
        # Check if the URL text contains { or }
        if '{' in cleaned_match or '}' in cleaned_match:
            # Enclose the URL text in backticks
            return cleaned_match[0] + '`' + cleaned_match[1:-1] + '`' + cleaned_match[-1]
        return cleaned_match
    
    # Replace all occurrences of the pattern with their escaped characters removed
    # and check for { or } to enclose in backticks
    corrected_content = re.sub(pattern, remove_escapes_and_check_braces, content)
    return corrected_content

def remove_index_block(content):
    """Remove the index block from the markdown content, starting after the first new line after '## Index'."""
    lines = content.split('\n')
    new_lines = []
    in_index_block = False
    past_first_new_line = False  # Track if we're past the first new line after '## Index'

    for line in lines:
        if line.startswith('## Index'):
            in_index_block = True
            continue
        if in_index_block and not past_first_new_line:
            if line.strip() == '':
                past_first_new_line = True  # We're past the first new line, start processing next lines
            continue  # Skip until we're past the first new line
        if in_index_block:
            if line.strip() == '' or not line.lstrip().startswith('-'):
                in_index_block = False  # End of index block
                continue
        else:
            new_lines.append(line)

    return '\n'.join(new_lines)

def process_header_blocks(content):
    """Process the parameters block of text as specified, including 'Setter Methods' and 'Execution Methods'."""
    lines = content.split('\n')
    processed_lines = []
    processing = False
    found_first_dash = False  # New variable to track the first dash

    for line in lines:
        if line.strip() in ['#### Parameters','#### Returns', '#### Setter Methods', '#### Execution Methods', '#### Methods', '#### Generated By']:
            processing = True
            found_first_dash = False  # Reset for each new section
            processed_lines.append(line)
            continue
        if processing:
            if not found_first_dash:
                if line.strip() == '':
                    processed_lines.append(line)
                    continue
                elif not line.startswith('-'):
                    processed_lines.append(line)
                    continue
                else:
                    found_first_dash = True  # Found the first dash, start processing lines
            if line.startswith('-'):
                # Step 1: Add a backtick after the dash and before the first colon
                line = line.replace('- ', '- `', 1)
                # Step 2: Replace the first colon with two new lines and two spaces
                line = line.replace(':', '`\n\n ', 1)
                # Step 3: Now, remove escape characters only between the backticks we've just added
                parts = line.split('`')
                if len(parts) > 2:  # Ensure there are backticks to process
                    parts[1] = parts[1].replace('\\', '')  # Remove escape characters only in the part between backticks
                    line = '`'.join(parts)
                # Step 4: Add an additional new line at the end
                line += '\n'
                processed_lines.append(line)
            else:
                # Stop processing if the line does not start with a dash
                processing = False
                processed_lines.append(line)
        else:
            processed_lines.append(line)

    return '\n'.join(processed_lines)

def remove_output_blocks(content):
    """Remove blocks of text starting with '// Output:' and ending with '```', including the start line but not the end line."""
    output_pattern = re.compile(r'// Output:.*?```', re.DOTALL)
    # Replace the found blocks with just '```' to keep the ending line
    cleaned_content = re.sub(output_pattern, '```', content)
    return cleaned_content

def add_tabs_tags(content):
    """Add opening and closing <Tabs> tags around groups of <TabItem> tags, considering blank lines."""
    lines = content.split('\n')
    new_lines = []
    in_tab_group = False

    def is_next_non_blank_line_tabitem(start_index, direction):
        """Check if the next non-blank line in the given direction (1 for forward, -1 for backward) is a <TabItem> line."""
        index = start_index + direction
        while 0 <= index < len(lines) and lines[index].strip() == '':
            index += direction
        if 0 <= index < len(lines):
            return lines[index].strip().startswith('<TabItem') if direction == 1 else lines[index].strip().endswith('</TabItem>')
        return False

    for i, line in enumerate(lines):
        trimmed_line = line.strip()
        # Check for opening <TabItem> without preceding closing </TabItem>
        if trimmed_line.startswith('<TabItem') and not is_next_non_blank_line_tabitem(i, -1):
            if not in_tab_group:
                new_lines.append('<Tabs>')
                in_tab_group = True
        new_lines.append(line)
        # Check for closing </TabItem> without following opening <TabItem>
        if trimmed_line.endswith('</TabItem>') and not is_next_non_blank_line_tabitem(i, 1):
            if in_tab_group:
                new_lines.append('</Tabs>')
                in_tab_group = False

    return '\n'.join(new_lines)

def convert_details_to_tabitem(content):
    """Convert <details> tags to <TabItem> with dynamic attributes based on the summary content, and remove the trailing <p>."""
    detail_pattern = re.compile(
        r'<details><summary>(.*?) \((.*?)\)</summary>\n<p>',
        re.DOTALL
    )
    return re.sub(detail_pattern, r'<TabItem value="\2" label="\1 (\2)">\n', content)

def read_file_content(file_path):
    """Read and return the content of the file."""
    try:
        with open(file_path, 'r') as file:
            return file.read()
    except FileNotFoundError:
        print(f"Error: The file {file_path} was not found.")
        return None

def write_file_content(file_path, content):
    """Write the given content to the file."""
    with open(file_path, 'w') as file:
        file.write(content)

def remove_pattern(content, patterns):
    """Remove all occurrences of the patterns from the content."""
    for pattern in patterns:
        pattern_str = r'\n?'.join([re.escape(part) for part in pattern])
        pattern_re = re.compile(pattern_str, re.DOTALL)
        content = re.sub(pattern_re, '', content, 1)
    return content

def replace_content(content, replacements):
    """Replace occurrences based on a dictionary of find-and-replace pairs."""
    for find, replace in replacements.items():
        content = content.replace(find, replace)
    return content

def process_file(file_path, patterns, replacements):
    """Process the file to remove specified patterns, replace specified strings, and convert <details> to <TabItem>, including removing the trailing <p>."""
    content = read_file_content(file_path)
    if content is not None:
        if patterns:
            content = remove_pattern(content, patterns)
        if replacements:
            content = replace_content(content, replacements)
        content = convert_details_to_tabitem(content)  # Convert <details> to <TabItem> and remove trailing <p>
        content = add_tabs_tags(content)  # Add <Tabs> and </Tabs> tags
        content = remove_output_blocks(content)  # Remove output blocks
        content = process_header_blocks(content)  # Process header blocks
        content = remove_index_block(content)  # Remove index block
        content = correct_escaping_in_links(content)  # Correct escaping in links
        content = move_all_struct_definitions(content) # Move all struct definitions
        content = add_anchor_tags(content)
        # content = add_anchor_tags_to_generated_by(content)  # Add anchor tags to 'Generated By' sections

        write_file_content(file_path, content)
        print(f"File {file_path} has been processed.")

def combine_files_into_mdx(file_paths, output_mdx_path):
    """Combine the content of multiple files into a single .mdx file and add specific text at the beginning based on a URL found in the content. Also, conditionally add import statements for Tabs and TabItem."""
    combined_content = ""
    output_filename = "combined_output.mdx"  # Default fallback filename
    for file_path in file_paths:
        with open(file_path, 'r') as file:
            combined_content += file.read() + "\n\n"  # Add some space between files

    # Use the global mapping
    global URL_TO_INFO

    # Search for a URL in the combined content
    for url, info in URL_TO_INFO.items():
        if url in combined_content:
            # If URL is found, prepare the text to be inserted
            header_text = f"---\ntitle: {info['title']}\nsidebar_position: {info['sidebar_position']}\n---\n\n"
            # Insert the text at the beginning of the combined content
            combined_content = header_text + combined_content
            # Update the output filename based on the title
            output_filename = f"{info['title'].lower().replace(' ', '_')}.mdx"
            break  # Assuming only one URL match is needed, break after the first match

    # Check for <Tabs> tag in the combined content
    if "<Tabs>" in combined_content:
        # Prepare the import statements
        import_statements = "import Tabs from \"@theme/Tabs\";\nimport TabItem from \"@theme/TabItem\";\n\n"
        # Insert the import statements after the header text
        combined_content = combined_content.replace("---\n\n", "---\n\n" + import_statements, 1)

    # Write the modified content to the dynamically determined output MDX file
    with open(output_filename, 'w') as output_file:
        output_file.write(combined_content)
    print(f"Combined MDX file created at {output_filename}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: ./process_markdown.py <file_path> [<file_path> ...]")
        sys.exit(1)
    
    patterns = [
        ['', '```go', 'import "."', '```', ''],
        ['# client'],
        ['# models'],
        ['Generated by [gomarkdoc](<https://github.com/princjef/gomarkdoc>)'],
        ['<!-- Code generated by gomarkdoc. DO NOT EDIT -->']
    ]
    replacements = {
        '### Setter Methods': '#### Setter Methods',
        '### Execution Methods': '#### Execution Methods',
        '### Methods': '#### Methods',
        '### Generated By': '#### Generated By',
        '</p>\n</details>': '</TabItem>'  # Generate closing MDX tabs
    }
    for file_path in sys.argv[1:]:
        process_file(file_path, patterns, replacements)    
    # Combine all processed files into a single .mdx file
    process_file_paths = sys.argv[1:]  # Assuming these are the paths of processed files
    combine_files_into_mdx(process_file_paths, "")  # No longer need to specify output_mdx_path here
